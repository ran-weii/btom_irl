{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D4RL data parsing\n",
    "* Compare the outputs of d4rl built-in data parsing method, a modification based on recorded next observations, and a custom fast parsing method\n",
    "* The main finding is that d4rl built-in parsing method incorrectly takes the initial obs of the next episode as the final next_obs of the current episode (have not verified if this is true for all episodes or just early terminated episodes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# filepath = \"../data/d4rl/halfcheetah-medium-expert-v2.p\"\n",
    "filepath = \"../data/d4rl/hopper-medium-expert-v2.p\"\n",
    "# filepath = \"../data/d4rl/walker2d-medium-expert-v2.p\"\n",
    "with open(filepath, \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs equivalent to next_obs by shift: True\n"
     ]
    }
   ],
   "source": [
    "# get first episode\n",
    "first_terminal = np.where((dataset[\"terminals\"] == 1) | (dataset[\"timeouts\"] == 1))[0][0]\n",
    "\n",
    "obs_eps = dataset[\"observations\"][:first_terminal]\n",
    "act_eps = dataset[\"actions\"][:first_terminal]\n",
    "rwd_eps = dataset[\"rewards\"][:first_terminal]\n",
    "next_obs_eps = dataset[\"next_observations\"][:first_terminal]\n",
    "\n",
    "print(\n",
    "    \"obs equivalent to next_obs by shift:\", \n",
    "    np.all((obs_eps[1:] - next_obs_eps[:-1]) == 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_d4rl(dataset, use_next_obs=False, terminate_on_end=False):\n",
    "    \"\"\" Parse dataset d4rl way \"\"\"\n",
    "    N = dataset['rewards'].shape[0]\n",
    "    obs_ = []\n",
    "    next_obs_ = []\n",
    "    action_ = []\n",
    "    reward_ = []\n",
    "    done_ = []\n",
    "    eps_id_ = []\n",
    "\n",
    "    # The newer version of the dataset adds an explicit\n",
    "    # timeouts field. Keep old method for backwards compatability.\n",
    "    use_timeouts = False\n",
    "    if 'timeouts' in dataset:\n",
    "        use_timeouts = True\n",
    "    \n",
    "    eps_id = 0\n",
    "    episode_step = 0\n",
    "    for i in range(N-1):\n",
    "        obs = dataset['observations'][i].astype(np.float32)\n",
    "        if use_next_obs:\n",
    "            new_obs = dataset['next_observations'][i].astype(np.float32)\n",
    "        else:\n",
    "            new_obs = dataset['observations'][i+1].astype(np.float32)\n",
    "        action = dataset['actions'][i].astype(np.float32)\n",
    "        reward = dataset['rewards'][i].astype(np.float32)\n",
    "        done_bool = bool(dataset['terminals'][i])\n",
    "\n",
    "        if use_timeouts:\n",
    "            final_timestep = dataset['timeouts'][i]\n",
    "        else:\n",
    "            final_timestep = (episode_step == 1000 - 1)\n",
    "        if (not terminate_on_end) and final_timestep:\n",
    "            # Skip this transition and don't apply terminals on the last step of an episode\n",
    "            episode_step = 0\n",
    "            continue\n",
    "\n",
    "        obs_.append(obs)\n",
    "        next_obs_.append(new_obs)\n",
    "        action_.append(action)\n",
    "        reward_.append(reward)\n",
    "        done_.append(done_bool)\n",
    "        eps_id_.append(eps_id)\n",
    "        episode_step += 1\n",
    "\n",
    "        if done_bool or final_timestep:\n",
    "            episode_step = 0\n",
    "            eps_id += 1\n",
    "\n",
    "    return {\n",
    "        \"obs\": np.array(obs_),\n",
    "        \"act\": np.array(action_),\n",
    "        \"rwd\": np.array(reward_).reshape(-1, 1),\n",
    "        \"next_obs\": np.array(next_obs_),\n",
    "        \"done\": np.array(done_).reshape(-1, 1),\n",
    "        \"eps_id\": np.array(eps_id_).reshape(-1, 1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_fast(dataset, skip_timeout=True):\n",
    "    \"\"\" Parse data fast and minimc d4rl parser when setting use_next_obs=True \"\"\"\n",
    "    # unpack dataset\n",
    "    obs = dataset[\"observations\"]\n",
    "    act = dataset[\"actions\"]\n",
    "    rwd = dataset[\"rewards\"].reshape(-1, 1)\n",
    "    next_obs = dataset[\"next_observations\"]\n",
    "    terminated = dataset[\"terminals\"].reshape(-1, 1)\n",
    "    \n",
    "    # follow d4rl qlearning_dataset\n",
    "    if skip_timeout:\n",
    "        obs = obs[dataset[\"timeouts\"] == False]\n",
    "        act = act[dataset[\"timeouts\"] == False]\n",
    "        rwd = rwd[dataset[\"timeouts\"] == False]\n",
    "        next_obs = next_obs[dataset[\"timeouts\"] == False]\n",
    "        terminated = terminated[dataset[\"timeouts\"] == False]\n",
    "    \n",
    "    return {\n",
    "        \"obs\": obs,\n",
    "        \"act\": act,\n",
    "        \"rwd\": rwd,\n",
    "        \"next_obs\": next_obs,\n",
    "        \"done\": terminated,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset_1 = parse_data_d4rl(dataset, use_next_obs=False)\n",
    "parsed_dataset_2 = parse_data_d4rl(dataset, use_next_obs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset_3 = parse_data_fast(dataset, skip_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_dataset_1 shape (1998966, 11)\n",
      "parsed_dataset_2 shape (1998966, 11)\n",
      "obs equal True\n",
      "next obs equal False\n",
      "done equal True\n"
     ]
    }
   ],
   "source": [
    "# d4rl parsing does not handle next_obs properly\n",
    "print(\"parsed_dataset_1 shape\", parsed_dataset_1[\"obs\"].shape)\n",
    "print(\"parsed_dataset_2 shape\", parsed_dataset_2[\"obs\"].shape)\n",
    "\n",
    "print(\"obs equal\",\n",
    "    len(np.unique(parsed_dataset_1[\"obs\"] - parsed_dataset_2[\"obs\"])) == 1\n",
    ")\n",
    "print(\"next obs equal\",\n",
    "    len(np.unique(parsed_dataset_1[\"next_obs\"] - parsed_dataset_2[\"next_obs\"])) == 1\n",
    ")\n",
    "print(\"done equal\",\n",
    "    len(np.unique(parsed_dataset_1[\"done\"] == parsed_dataset_2[\"done\"])) == 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_dataset_3 shape (1998319, 17)\n",
      "obs equal True\n",
      "next obs equal True\n",
      "done equal True\n"
     ]
    }
   ],
   "source": [
    "# fast parsing is equal to parsing with use_next_obs=True\n",
    "print(\"parsed_dataset_3 shape\", parsed_dataset_3[\"obs\"].shape)\n",
    "\n",
    "print(\"obs equal\",\n",
    "    len(np.unique(parsed_dataset_2[\"obs\"] - parsed_dataset_3[\"obs\"][:-1])) == 1\n",
    ")\n",
    "print(\"next obs equal\",\n",
    "    len(np.unique(parsed_dataset_2[\"next_obs\"] - parsed_dataset_3[\"next_obs\"][:-1])) == 1\n",
    ")\n",
    "print(\"done equal\",\n",
    "    len(np.unique(parsed_dataset_2[\"done\"] == parsed_dataset_3[\"done\"][:-1])) == 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check why next obs is not equal\n",
    "next_obs_not_equal = np.any(\n",
    "    (parsed_dataset_1[\"next_obs\"] - parsed_dataset_2[\"next_obs\"]) != 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_next_obs=False\n",
      "[[ 0.    0.89  0.59 -0.05 -0.77  0.88  0.6  -0.04 -0.74  0.    0.  ]\n",
      " [ 0.    0.88  0.6  -0.04 -0.74  0.86  0.6  -0.05 -0.69  0.    0.  ]\n",
      " [ 0.    0.86  0.6  -0.05 -0.69  0.84  0.62 -0.02 -0.68  0.    0.  ]\n",
      " [ 0.    0.84  0.62 -0.02 -0.68  0.82  0.62 -0.01 -0.73  0.    0.  ]\n",
      " [ 0.    0.82  0.62 -0.01 -0.73  0.8   0.63  0.02 -0.81  0.    0.  ]\n",
      " [ 0.    0.8   0.63  0.02 -0.81  1.25 -0.    0.   -0.    1.    1.  ]\n",
      " [ 1.    1.25 -0.    0.   -0.    1.25 -0.03 -0.03  0.    0.    0.  ]\n",
      " [ 1.    1.25 -0.03 -0.03  0.    1.24 -0.08 -0.09  0.01  0.    0.  ]\n",
      " [ 1.    1.24 -0.08 -0.09  0.01  1.24 -0.12 -0.12 -0.03  0.    0.  ]\n",
      " [ 1.    1.24 -0.12 -0.12 -0.03  1.23 -0.15 -0.13 -0.05  0.    0.  ]]\n",
      "\n",
      "use_next_obs=True\n",
      "[[ 0.    0.89  0.59 -0.05 -0.77  0.88  0.6  -0.04 -0.74  0.    0.  ]\n",
      " [ 0.    0.88  0.6  -0.04 -0.74  0.86  0.6  -0.05 -0.69  0.    0.  ]\n",
      " [ 0.    0.86  0.6  -0.05 -0.69  0.84  0.62 -0.02 -0.68  0.    0.  ]\n",
      " [ 0.    0.84  0.62 -0.02 -0.68  0.82  0.62 -0.01 -0.73  0.    0.  ]\n",
      " [ 0.    0.82  0.62 -0.01 -0.73  0.8   0.63  0.02 -0.81  0.    0.  ]\n",
      " [ 0.    0.8   0.63  0.02 -0.81  0.78  0.64  0.06 -0.91  1.    1.  ]\n",
      " [ 1.    1.25 -0.    0.   -0.    1.25 -0.03 -0.03  0.    0.    0.  ]\n",
      " [ 1.    1.25 -0.03 -0.03  0.    1.24 -0.08 -0.09  0.01  0.    0.  ]\n",
      " [ 1.    1.24 -0.08 -0.09  0.01  1.24 -0.12 -0.12 -0.03  0.    0.  ]\n",
      " [ 1.    1.24 -0.12 -0.12 -0.03  1.23 -0.15 -0.13 -0.05  0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# compare two parsing methods around time step where they are different\n",
    "t_not_equal = np.where(next_obs_not_equal)[0][0]\n",
    "\n",
    "obs_window_1 = np.hstack([\n",
    "    parsed_dataset_1[\"eps_id\"][t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "    parsed_dataset_1[\"obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_1[\"next_obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_1[\"done\"][t_not_equal-5:t_not_equal+5],\n",
    "    next_obs_not_equal[t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "]).round(2)\n",
    "\n",
    "obs_window_2 = np.hstack([\n",
    "    parsed_dataset_2[\"eps_id\"][t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "    parsed_dataset_2[\"obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_2[\"next_obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_2[\"done\"][t_not_equal-5:t_not_equal+5],\n",
    "    next_obs_not_equal[t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "]).round(2)\n",
    "\n",
    "print(\"use_next_obs=False\")\n",
    "print(obs_window_1)\n",
    "print()\n",
    "print(\"use_next_obs=True\")\n",
    "print(obs_window_2)\n",
    "\n",
    "# big jump in final step if not use_next_obs (d4rl implementation is wrong?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_next_obs=False\n",
      "[[ 1.    0.89  0.8  -0.1  -0.7   0.87  0.79 -0.11 -0.76  0.    0.  ]\n",
      " [ 1.    0.87  0.79 -0.11 -0.76  0.86  0.78 -0.11 -0.84  0.    0.  ]\n",
      " [ 1.    0.86  0.78 -0.11 -0.84  0.84  0.78 -0.09 -0.93  0.    0.  ]\n",
      " [ 1.    0.84  0.78 -0.09 -0.93  0.83  0.78 -0.07 -1.03  0.    0.  ]\n",
      " [ 1.    0.83  0.78 -0.07 -1.03  0.81  0.75 -0.09 -1.12  0.    0.  ]\n",
      " [ 1.    0.81  0.75 -0.09 -1.12  1.25  0.    0.    0.    1.    1.  ]\n",
      " [ 2.    1.25  0.    0.    0.    1.25 -0.03 -0.04  0.    0.    0.  ]\n",
      " [ 2.    1.25 -0.03 -0.04  0.    1.25 -0.08 -0.09  0.01  0.    0.  ]\n",
      " [ 2.    1.25 -0.08 -0.09  0.01  1.24 -0.1  -0.11 -0.02  0.    0.  ]\n",
      " [ 2.    1.24 -0.1  -0.11 -0.02  1.23 -0.12 -0.1  -0.08  0.    0.  ]]\n",
      "\n",
      "use_next_obs=True\n",
      "[[ 1.    0.89  0.8  -0.1  -0.7   0.87  0.79 -0.11 -0.76  0.    0.  ]\n",
      " [ 1.    0.87  0.79 -0.11 -0.76  0.86  0.78 -0.11 -0.84  0.    0.  ]\n",
      " [ 1.    0.86  0.78 -0.11 -0.84  0.84  0.78 -0.09 -0.93  0.    0.  ]\n",
      " [ 1.    0.84  0.78 -0.09 -0.93  0.83  0.78 -0.07 -1.03  0.    0.  ]\n",
      " [ 1.    0.83  0.78 -0.07 -1.03  0.81  0.75 -0.09 -1.12  0.    0.  ]\n",
      " [ 1.    0.81  0.75 -0.09 -1.12  0.79  0.74 -0.09 -1.2   1.    1.  ]\n",
      " [ 2.    1.25  0.    0.    0.    1.25 -0.03 -0.04  0.    0.    0.  ]\n",
      " [ 2.    1.25 -0.03 -0.04  0.    1.25 -0.08 -0.09  0.01  0.    0.  ]\n",
      " [ 2.    1.25 -0.08 -0.09  0.01  1.24 -0.1  -0.11 -0.02  0.    0.  ]\n",
      " [ 2.    1.24 -0.1  -0.11 -0.02  1.23 -0.12 -0.1  -0.08  0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# compare two parsing methods around time step where they are different\n",
    "t_not_equal = np.where(next_obs_not_equal)[0][1]\n",
    "\n",
    "obs_window_1 = np.hstack([\n",
    "    parsed_dataset_1[\"eps_id\"][t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "    parsed_dataset_1[\"obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_1[\"next_obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_1[\"done\"][t_not_equal-5:t_not_equal+5],\n",
    "    next_obs_not_equal[t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "]).round(2)\n",
    "\n",
    "obs_window_2 = np.hstack([\n",
    "    parsed_dataset_2[\"eps_id\"][t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "    parsed_dataset_2[\"obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_2[\"next_obs\"][t_not_equal-5:t_not_equal+5, :4],\n",
    "    parsed_dataset_2[\"done\"][t_not_equal-5:t_not_equal+5],\n",
    "    next_obs_not_equal[t_not_equal-5:t_not_equal+5].reshape(-1, 1),\n",
    "]).round(2)\n",
    "\n",
    "print(\"use_next_obs=False\")\n",
    "print(obs_window_1)\n",
    "print()\n",
    "print(\"use_next_obs=True\")\n",
    "print(obs_window_2)\n",
    "\n",
    "# big jump in final step if not use_next_obs (d4rl implementation is wrong?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check between step observation difference\n",
    "obs_mean = parsed_dataset_1[\"obs\"].mean(0)\n",
    "obs_std = parsed_dataset_1[\"obs\"].std(0)\n",
    "\n",
    "obs_diff_1 = np.abs(\n",
    "    (parsed_dataset_1[\"next_obs\"] - obs_mean) / obs_std - \\\n",
    "    (parsed_dataset_1[\"obs\"] - obs_mean) / obs_std\n",
    ")\n",
    "\n",
    "obs_diff_2 = np.abs(\n",
    "    (parsed_dataset_2[\"next_obs\"] - obs_mean) / obs_std - \\\n",
    "    (parsed_dataset_2[\"obs\"] - obs_mean) / obs_std\n",
    ")\n",
    "\n",
    "obs_diff_1_75_percent = pd.DataFrame(obs_diff_1).describe().iloc[6].values\n",
    "obs_diff_1_max = pd.DataFrame(obs_diff_1).describe().iloc[7].values\n",
    "\n",
    "obs_diff_2_75_percent = pd.DataFrame(obs_diff_2).describe().iloc[6].values\n",
    "obs_diff_2_max = pd.DataFrame(obs_diff_2).describe().iloc[7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare 75 percentile\n",
      "[[0.073 0.041 0.095 0.104 0.062 0.018 0.096 0.104 0.126 0.191 0.401 0.431\n",
      "  0.582 0.224 0.248 0.446 0.317]\n",
      " [0.073 0.041 0.095 0.104 0.062 0.018 0.096 0.104 0.126 0.191 0.401 0.431\n",
      "  0.582 0.224 0.248 0.446 0.316]]\n",
      "compare max\n",
      "[[ 4.565  3.858  7.849 11.142  2.052 11.057  7.137  2.266  5.334  6.22\n",
      "   9.789  9.181  6.103  4.196 17.067  4.046  3.395]\n",
      " [ 0.391  1.06   2.325  2.173  1.002  2.431  1.081  1.072  1.691  2.676\n",
      "   9.789  9.181  6.103  4.196 17.067  4.046  3.395]]\n"
     ]
    }
   ],
   "source": [
    "print(\"compare 75 percentile\")\n",
    "print(np.stack([obs_diff_1_75_percent, obs_diff_2_75_percent]).round(3))\n",
    "\n",
    "print(\"compare max\")\n",
    "print(np.stack([obs_diff_1_max, obs_diff_2_max]).round(3))\n",
    "\n",
    "# d4rl parsing methods incurr significant error "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b67c7bf2c4878826dcfa43818fc86128ef4fa9ed627e264d0f28858c4a426f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
